import os
import requests
import time
import random
from bs4 import BeautifulSoup
from supabase import create_client, Client

# 1. ì„¤ì •
URL = os.environ.get("SUPABASE_URL")
KEY = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(URL, KEY)

def get_web_detail(session, item_seq):
    """
    [ìƒì„¸ ìˆ˜ì§‘] ì œí’ˆëª… í´ë¦­ ì‹œ ì´ë™í•˜ëŠ” ìƒì„¸ í˜ì´ì§€(CCBBB01) ë°ì´í„° ìˆ˜ì§‘
    """
    url = f"https://nedrug.mfds.go.kr/pbp/CCBBB01/getItemDetail?itemSeq={item_seq}"
    try:
        res = session.get(url, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # 1. ìœ„íƒì œì¡°ì—…ì²´ (í…Œì´ë¸” ìŠ¤ìº”)
        manufacturer = "ìì‚¬ì œì¡°" 
        tables = soup.select("table.view_table")
        for table in tables:
            if "ì œì¡°ì†Œ" in table.text:
                rows = table.select("tr")
                for row in rows:
                    if "ìœ„íƒ" in row.text or "ìˆ˜íƒ" in row.text:
                        manufacturer = row.select_one("td").text.strip()
                        break
        
        # 2. ì„±ë¶„ëª…
        ingredients = "ìƒì„¸ì„±ë¶„ ì°¸ì¡°"
        
        # 3. íš¨ëŠ¥íš¨ê³¼ (IDë¡œ ì¶”ì¶œ)
        efficacy = "ìƒì„¸ íš¨ëŠ¥íš¨ê³¼ ì°¸ì¡°"
        ee_data = soup.select_one("#ee_doc_data")
        if ee_data:
            efficacy = ee_data.text.strip()[:500]

        return manufacturer, ingredients, efficacy

    except Exception:
        return "ìˆ˜ì§‘ì‹¤íŒ¨", "ìˆ˜ì§‘ì‹¤íŒ¨", "ìˆ˜ì§‘ì‹¤íŒ¨"

def main():
    print("=== ğŸ§ª ì…˜ íŒ€ì¥ë‹˜ í…ŒìŠ¤íŠ¸: '2ì›” 1ì£¼ì°¨(ë°ì´í„° ìœ )' ê²€ì¦ ì‹œì‘ ===")
    
    session = requests.Session()
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
        'Referer': 'https://nedrug.mfds.go.kr/pbp/CCBAE01'
    }
    
    target_url = "https://nedrug.mfds.go.kr/pbp/CCBAE01/getItemPermitIntro"
    
    # 1ì£¼ì°¨ëŠ” ë°ì´í„°ê°€ 43ê±´ì´ë¯€ë¡œ 1~5í˜ì´ì§€ë©´ ì¶©ë¶„
    total_saved = 0
    
    for page in range(1, 6):
        print(f"\n>> [Web] {page}í˜ì´ì§€ ìŠ¤ìº” ì¤‘ (ê¸°ê°„: 2/1 ~ 2/7)...")
        
        # [í•µì‹¬] 2ì›” 1ì£¼ì°¨ë¡œ íƒ€ê²Ÿ ë³€ê²½
        params = {
            'page': page,
            'limit': '10',
            'sort': 'itemPermitDate',
            'sortOrder': 'true',
            'searchYn': 'true',
            'sDateGb': 'date', # ì •í™•í•œ ë‚ ì§œ ì§€ì •ì„ ìœ„í•´ date ëª¨ë“œ ì‚¬ìš©
            'sYear': '2026',
            'sMonth': '2',
            'sWeek': '1',
            'sPermitDateStart': '2026-02-01', # ì‹œì‘ì¼ (1ì£¼ì°¨)
            'sPermitDateEnd': '2026-02-07',   # ì¢…ë£Œì¼ (1ì£¼ì°¨)
            'btnSearch': 'ê²€ìƒ‰'
        }

        try:
            res = session.get(target_url, params=params, headers=headers, timeout=30)
            soup = BeautifulSoup(res.text, 'html.parser')
            rows = soup.select('table.board_list tbody tr')

            if not rows or "ë°ì´í„°ê°€" in rows[0].text:
                print(">> ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break

            for row in rows:
                cols = row.find_all('td')
                if len(cols) < 8: continue

                # ì›¹ì‚¬ì´íŠ¸ ì»¬ëŸ¼ ì¸ë±ìŠ¤ (ë³€ë™ ê°€ëŠ¥ì„± ìˆìœ¼ë‚˜ ë³´í†µ ì´ ìˆœì„œ)
                # 0:ë²ˆí˜¸, 1:ì œí’ˆëª…, 2:ì—…ì²´ëª…, 3:í—ˆê°€ì¼, 4:ì·¨ì†Œì¼, 5:ìƒíƒœ, 6:êµ¬ë¶„...
                product_name = cols[1].text.strip()
                company = cols[2].text.strip()
                approval_date = cols[3].text.strip()
                cancel_date = cols[4].text.strip() 

                # [í•„í„°ë§] ì·¨ì†Œì¼ìê°€ ìˆìœ¼ë©´(ê°’ì´ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´) íŒ¨ìŠ¤
                if cancel_date:
                    print(f"   -> [ê±°ë¦„] {product_name} (ì·¨ì†Œë¨: {cancel_date})")
                    continue
                
                try:
                    item_seq = cols[1].find('a')['onclick'].split("'")[1]
                except:
                    continue

                print(f"   -> [ìˆ˜ì§‘] {product_name} ({approval_date})")
                
                # ìƒì„¸ ì •ë³´ ê¸ì–´ì˜¤ê¸°
                manufacturer, ingredients, efficacy = get_web_detail(session, item_seq)

                data = {
                    "item_seq": item_seq,
                    "product_name": product_name,
                    "company": company,
                    "manufacturer": manufacturer, 
                    "category": "ì „ë¬¸ì˜ì•½í’ˆ" if "ì „ë¬¸" in row.text else "ì¼ë°˜ì˜ì•½í’ˆ",
                    "approval_type": "ì •ìƒ",
                    "ingredients": ingredients,
                    "efficacy": efficacy,
                    "approval_date": approval_date,
                    "detail_url": f"https://nedrug.mfds.go.kr/pbp/CCBBB01/getItemDetail?itemSeq={item_seq}"
                }
                
                supabase.table("drug_approvals").upsert(data).execute()
                total_saved += 1
                time.sleep(random.uniform(0.5, 1.0))

        except Exception as e:
            print(f"âš ï¸ ì—ëŸ¬: {e}")
            continue

    print(f"\n=== ğŸ† ê²€ì¦ ì™„ë£Œ: 1ì£¼ì°¨ ë°ì´í„° ì´ {total_saved}ê±´ ìˆ˜ì§‘ë¨ ===")

if __name__ == "__main__":
    main()
