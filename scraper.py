import os
import requests
import time
from datetime import datetime
from bs4 import BeautifulSoup
from supabase import create_client, Client

# 1. Supabase ì„¤ì • (ì ˆëŒ€ ìˆ˜ì • ê¸ˆì§€)
URL = os.environ.get("SUPABASE_URL")
KEY = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(URL, KEY)

def main():
    print("=== ğŸš¨ ì…˜ íŒ€ì¥ë‹˜ ì „ìš©: ì‹ì•½ì²˜ ë³´ì•ˆ ì™„ì „ ì •ë³µ ì‘ì „ ì‹œì‘ ===")
    
    # [ì„¤ì •] 2ì›” 1ì¼ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€ (41ê±´ ì •ë°€ íƒ€ê²© ê¸°ê°„)
    s_start = "2026-02-01"
    s_end = datetime.now().strftime("%Y-%m-%d")
    
    session = requests.Session()
    # í†µí–‰ì¦(Cookie) ë°œê¸‰ì„ ìœ„í•œ ì²« ë°©ë¬¸
    session.get("https://nedrug.mfds.go.kr/pbp/CCBAE01", timeout=20)
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36',
        'Referer': 'https://nedrug.mfds.go.kr/pbp/CCBAE01',
        'Content-Type': 'application/x-www-form-urlencoded'
    }

    total_saved = 0

    # 41ê±´ ìˆ˜ì§‘ì„ ìœ„í•´ 1~5í˜ì´ì§€ ìˆœì°¨ ê³µëµ
    for page in range(1, 6):
        print(f"\n>> [ {page} í˜ì´ì§€ ] ë°ì´í„° ê°•ì œ ì¸ì¶œ ì¤‘...")
        
        # ì„œë²„ê°€ "ì‚¬ëŒì´ ê²€ìƒ‰í–ˆë‹¤"ê³  ë¯¿ê²Œ ë§Œë“œëŠ” í•„ìˆ˜ íŒŒë¼ë¯¸í„° ì¡°í•©
        payload = {
            'page': page,
            'limit': '10',
            'searchYn': 'true',
            'sDateGb': 'date', # ì¼ìê²€ìƒ‰ ëª¨ë“œ í™œì„±í™”
            'sPermitDateStart': s_start,
            'sPermitDateEnd': s_end,
            'btnSearch': 'ê²€ìƒ‰'
        }

        try:
            res = session.post("https://nedrug.mfds.go.kr/pbp/CCBAE01/getItemPermitIntro", 
                               headers=headers, data=payload, timeout=30)
            
            soup = BeautifulSoup(res.text, 'html.parser')
            rows = soup.select('table.board_list tbody tr')

            if not rows or "ë°ì´í„°ê°€" in rows[0].get_text():
                print("ìˆ˜ì§‘ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break

            for row in rows:
                cols = row.find_all('td')
                if len(cols) < 5 or cols[4].get_text(strip=True): continue 

                product_name = cols[1].get_text(strip=True)
                item_seq = cols[1].find('a')['onclick'].split("'")[1]

                print(f"   -> ê¸ˆê³  ì•ˆì°©: {product_name}")
                
                # íŒ€ì¥ë‹˜ì´ ìš”ì²­í•˜ì‹  7ê°€ì§€ í•­ëª© êµ¬ì¡°ë¡œ ë°ì´í„° ìƒì„±
                data = {
                    "item_seq": item_seq,
                    "product_name": product_name,
                    "company": cols[2].get_text(strip=True),
                    "manufacturer": "ìƒì„¸ì •ë³´ ìˆ˜ì§‘ ì¤‘", # ìƒì„¸í˜ì´ì§€ ì¶”ê°€ ìˆ˜ì§‘ìš©
                    "category": "ì „ë¬¸ì˜ì•½í’ˆ" if "ì „ë¬¸" in product_name else "ì¼ë°˜ì˜ì•½í’ˆ", 
                    "approval_type": "í’ˆëª©í—ˆê°€",
                    "ingredients": "ë°ì´í„° ë¡œë”© ì¤‘",
                    "efficacy": "ë°ì´í„° ë¡œë”© ì¤‘",
                    "approval_date": cols[3].get_text(strip=True),
                    "detail_url": f"https://nedrug.mfds.go.kr/pbp/CCBBB01/getItemDetail?itemSeq={item_seq}"
                }
                
                # Supabase ì €ì¥ (Upsert)
                supabase.table("drug_approvals").upsert(data).execute()
                total_saved += 1

            time.sleep(1)

        except Exception as e:
            print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ: {e}")
            continue

    print(f"\n=== ğŸ† ì„±ê³µ: ì´ {total_saved}ê±´ì´ ê¸ˆê³ ì— ì•ˆì°©í–ˆìŠµë‹ˆë‹¤! ===")

if __name__ == "__main__":
    main()
