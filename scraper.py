import os
import requests
import time
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
from supabase import create_client, Client

# 1. ì„¤ì •
API_KEY = "2b03726584036b06c8c1c6b3d385a73be48f35cceac5444bcd6c611db5de7972"
URL = os.environ.get("SUPABASE_URL")
KEY = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(URL, KEY)

def get_api_detail(item_seq):
    """ [ìƒì„¸ API] ì œí’ˆë²ˆí˜¸ë¡œ ì„±ë¶„, íš¨ëŠ¥, ì œì¡°ì› ì¡°íšŒ """
    url = "http://apis.data.go.kr/1471000/DrugPrdtPrmsnInfoService07/getDrugPrdtPrmsnDtlInq06"
    params = {'serviceKey': API_KEY, 'item_seq': item_seq, 'numOfRows': '1', 'type': 'xml'}
    try:
        res = requests.get(url, params=params, timeout=10)
        root = ET.fromstring(res.text)
        item = root.find('.//item')
        if not item: return "ì •ë³´ì—†ìŒ", "ì •ë³´ì—†ìŒ", "ìƒì„¸ì°¸ì¡°"
        
        manufacturer = item.findtext('MANU_METHOD') or "ì •ë³´ì—†ìŒ"
        ingredients = item.findtext('MAIN_ITEM_INGR') or "ì •ë³´ì—†ìŒ"
        efficacy = BeautifulSoup(item.findtext('EE_DOC_DATA') or "ìƒì„¸ì°¸ì¡°", "html.parser").get_text()[:500]
        return manufacturer, ingredients, efficacy
    except:
        return "ì¡°íšŒì‹¤íŒ¨", "ì¡°íšŒì‹¤íŒ¨", "ì¡°íšŒì‹¤íŒ¨"

def main():
    print("=== ğŸŒŸ ì…˜ íŒ€ì¥ë‹˜ ì§€ì‹œ: ì„¸ì…˜ íšë“ í›„ 43ê±´ ì •ë°€ íƒ€ê²© ì‹œì‘ ===")
    
    # ì„¸ì…˜ ìœ ì§€ë¥¼ ìœ„í•œ ê°ì²´ ìƒì„±
    session = requests.Session()
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
        'Referer': 'https://nedrug.mfds.go.kr/pbp/CCBAE01'
    }
    
    # [1ë‹¨ê³„] ë©”ì¸ í˜ì´ì§€ ë¨¼ì € ë°©ë¬¸í•˜ì—¬ 'ì…ì¥ê¶Œ(Cookie)' íšë“ (ë§¤ìš° ì¤‘ìš”!)
    print(">> [ì…ì¥] ì‹ì•½ì²˜ ë¡œë¹„(ë©”ì¸í˜ì´ì§€)ì—ì„œ í†µí–‰ì¦ ë°œê¸‰ ì¤‘...")
    session.get("https://nedrug.mfds.go.kr/pbp/CCBAE01", headers=headers, timeout=30)
    time.sleep(1) # ë„ì¥ ì°ëŠ” ì‹œê°„ ëŒ€ê¸°

    # [2ë‹¨ê³„] íŒ€ì¥ë‹˜ì´ í™•ì¸í•˜ì‹  íŒŒë¼ë¯¸í„° ê·¸ëŒ€ë¡œ ëª©ë¡ ìš”ì²­
    target_url = "https://nedrug.mfds.go.kr/pbp/CCBAE01/getItemPermitIntro"
    total_saved = 0
    
    # 43ê±´ì´ë©´ ë„‰ë„‰íˆ 1~5í˜ì´ì§€ ìŠ¤ìº”
    for page in range(1, 6): 
        print(f"\n>> [Web] {page}í˜ì´ì§€ ëª©ë¡ ìŠ¤ìº” ì¤‘...")
        
        params = {
            'page': page,
            'limit': '10',
            'sort': '',
            'sortOrder': 'true',
            'searchYn': 'true',
            'sDateGb': 'date',
            'sYear': '2026',
            'sMonth': '2',
            'sWeek': '2', 
            'sPermitDateStart': '2026-02-01', # íŒ€ì¥ë‹˜ ì„¤ì • ë‚ ì§œ
            'sPermitDateEnd': '2026-02-14',   # íŒ€ì¥ë‹˜ ì„¤ì • ë‚ ì§œ
            'btnSearch': '',
            'garaInputBox': '' # ë¸Œë¼ìš°ì € URLì— ìˆë˜ ë”ë¯¸ íŒŒë¼ë¯¸í„°ê¹Œì§€ ì™„ë²½ ë³µì œ
        }

        try:
            # ì„¸ì…˜(ì…ì¥ê¶Œ)ì„ ë“¤ê³  GET ìš”ì²­
            res = session.get(target_url, params=params, headers=headers, timeout=30)
            soup = BeautifulSoup(res.text, 'html.parser')
            rows = soup.select('table.board_list tbody tr')

            if not rows or "ë°ì´í„°ê°€" in rows[0].text:
                print(">> ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ìˆ˜ì§‘ ì¢…ë£Œ)")
                break

            for row in rows:
                cols = row.find_all('td')
                if len(cols) < 5: continue

                product_name = cols[1].text.strip()
                item_seq = cols[1].find('a')['onclick'].split("'")[1]
                
                print(f"   -> [ë°œê²¬] {product_name} ({item_seq})")
                
                # [3ë‹¨ê³„] APIë¡œ ë¹ˆì¹¸(ì„±ë¶„/ì œì¡°ì›) ì±„ìš°ê¸°
                manufacturer, ingredients, efficacy = get_api_detail(item_seq)

                data = {
                    "item_seq": item_seq,
                    "product_name": product_name,
                    "company":
