import os
import requests
import time
import math
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
from supabase import create_client, Client

# 1. ì„¤ì •
API_KEY = "2b03726584036b06c8c1c6b3d385a73be48f35cceac5444bcd6c611db5de7972"
URL = os.environ.get("SUPABASE_URL")
KEY = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(URL, KEY)

def get_api_detail(item_seq):
    """ [ìƒì„¸ API] ì œì¡°ì›, ì„±ë¶„, íš¨ëŠ¥ ë“± ì¶”ê°€ ì •ë³´ ì¡°íšŒ """
    url = "http://apis.data.go.kr/1471000/DrugPrdtPrmsnInfoService07/getDrugPrdtPrmsnDtlInq06"
    params = {'serviceKey': API_KEY, 'item_seq': item_seq, 'numOfRows': '1', 'type': 'xml'}
    try:
        res = requests.get(url, params=params, timeout=10)
        root = ET.fromstring(res.text)
        item = root.find('.//item')
        if not item: return None

        return {
            'date': item.findtext('ITEM_PERMIT_DATE') or item.findtext('PERMIT_DATE'),
            'manu': item.findtext('MANU_METHOD') or "ì •ë³´ì—†ìŒ",
            'ingr': item.findtext('MAIN_ITEM_INGR') or item.findtext('ITEM_INGR_NAME') or "ì •ë³´ì—†ìŒ",
            'effi': BeautifulSoup(item.findtext('EE_DOC_DATA') or "ìƒì„¸ì°¸ì¡°", "html.parser").get_text()[:500]
        }
    except:
        return None

def main():
    print("=== ğŸŒŸ ì…˜ íŒ€ì¥ë‹˜ ìµœì¢… ì§€ì‹œ: '2026ë…„ ì½”ë“œ' í•„í„°ë§ìœ¼ë¡œ ì •í™•ë„ 100% í™•ë³´ ===")
    
    list_url = "http://apis.data.go.kr/1471000/DrugPrdtPrmsnInfoService07/getDrugPrdtPrmsnInq07"
    
    # [1ë‹¨ê³„] ì „ì²´ í˜ì´ì§€ íŒŒì•…
    print(">> [ì •ì°°] ë°ì´í„° ê·œëª¨ í™•ì¸ ì¤‘...")
    try:
        res = requests.get(list_url, params={'serviceKey': API_KEY, 'numOfRows': '1', 'type': 'xml'}, timeout=10)
        total_count = int(ET.fromstring(res.text).findtext('.//totalCount'))
        last_page = math.ceil(total_count / 100)
        print(f">> ì´ {total_count}ê±´. ìµœì‹  ë°ì´í„°(ë³€ê²½ë¶„ í¬í•¨)ëŠ” {last_page}í˜ì´ì§€ì— ìˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ API ì ‘ì† ì‹¤íŒ¨: {e}")
        return

    total_saved = 0
    
    # [2ë‹¨ê³„] ì—­ìˆœ ìŠ¤ìº” (ë§ˆì§€ë§‰ í˜ì´ì§€ë¶€í„° ë’¤ë¡œ 20í˜ì´ì§€)
    # ìµœê·¼ì— 'ì·¨ì†Œ'ëœ ì˜›ë‚  ì•½ë“¤ì´ ë’¤ìª½ì— ëª°ë ¤ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë„‰ë„‰í•˜ê²Œ 20í˜ì´ì§€ë¥¼ í›‘ì–´ì„œ '2026ë…„ìƒ'ì„ ì°¾ìŠµë‹ˆë‹¤.
    scan_depth = 20
    
    for page in range(last_page, last_page - scan_depth, -1):
        if page < 1: break
        
        print(f"\n>> [API] {page}í˜ì´ì§€ ì •ë°€ ì„ ë³„ ì¤‘...")
        
        params = {
            'serviceKey': API_KEY,
            'pageNo': str(page),
            'numOfRows': '100',
            'type': 'xml'
        }
        
        try:
            res = requests.get(list_url, params=params, timeout=30)
            items = ET.fromstring(res.text).findall('.//item')
            if not items: continue

            # ìµœì‹ ìˆœ(ì—­ìˆœ) ìˆœíšŒ
            for item in reversed(items):
                product_name = item.findtext('ITEM_NAME')
                
                # 1. ì·¨ì†Œ ì—¬ë¶€ í™•ì¸ (ì·¨ì†Œëœ ì•½ì€ ë²„ë¦¼)
                cancel_date = item.findtext('CANCEL_DATE')
                if cancel_date:
                    # ë¡œê·¸ë¥¼ ë„ˆë¬´ ë§ì´ ì°ì§€ ì•Šê¸° ìœ„í•´ ì·¨ì†Œëœ ê±´ì€ ì¡°ìš©íˆ íŒ¨ìŠ¤í•˜ê±°ë‚˜ í•„ìš”ì‹œ ì£¼ì„ í•´ì œ
                    # print(f"   -> [ê±°ë¦„] {product_name} (ì·¨ì†Œë¨)") 
                    continue

                # 2. [í•µì‹¬] í’ˆëª©ê¸°ì¤€ì½”ë“œ(PRDLST_STDR_CODE) í™•ì¸
                code = item.findtext('PRDLST_STDR_CODE') or ""
                
                # ì½”ë“œê°€ "2026"ìœ¼ë¡œ ì‹œì‘í•˜ì§€ ì•Šìœ¼ë©´? -> ì˜›ë‚  ì•½ì„ -> íŒ¨ìŠ¤!
                if not code.startswith("2026"):
                    continue
                
                # ì—¬ê¸°ê¹Œì§€ ì™”ìœ¼ë©´ "2026ë…„ì— íƒœì–´ë‚œ ì‚´ì•„ìˆëŠ” ì•½"ì…ë‹ˆë‹¤.
                item_seq = item.findtext('ITEM_SEQ')
                
                # ìƒì„¸ ì •ë³´ ì¡°íšŒ
                detail = get_api_detail(item_seq)
                if not detail or not detail['date']: continue
                
                real_date = detail['date'].replace("-", "").replace(".", "")
                
                print(f"   -> [ğŸ’ë°œêµ´] {product_name} (ì½”ë“œ:{code}, ì¼ì:{real_date})")
                
                data = {
                    "item_seq": item_seq,
                    "product_name": product_name,
                    "company": item.findtext('ENTP_NAME'),
                    "manufacturer": detail['manu'],
                    "category": item.findtext('SPCLTY_PBLC') or "êµ¬ë¶„ì—†ìŒ",
                    "approval_type": "ì •ìƒ",
                    "ingredients": detail['ingr'],
                    "efficacy": detail['effi'],
                    "approval_date": real_date,
                    "detail_url": f"https://nedrug.mfds.go.kr/pbp/CCBBB01/getItemDetail?itemSeq={item_seq}"
                }
                
                supabase.table("drug_approvals").upsert(data).execute()
                total_saved += 1
                time.sleep(0.05)

    
        except Exception as e:
            print(f"âš ï¸ ì—ëŸ¬: {e}")
            continue

    print(f"\n=== ğŸ† ìˆ˜ì§‘ ì™„ë£Œ: ì¡ë™ì‚¬ë‹ˆ ì œê±° í›„ 'ìˆœìˆ˜ 2026ë…„ ì‹ ì•½' {total_saved}ê±´ í™•ë³´! ===")

if __name__ == "__main__":
    main()
