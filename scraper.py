import os
import requests
import time
from datetime import datetime
from bs4 import BeautifulSoup
from supabase import create_client, Client
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# 1. Supabase ì„¤ì •
URL = os.environ.get("SUPABASE_URL")
KEY = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(URL, KEY)

def main():
    print("=== ğŸš€ ì…˜ íŒ€ì¥ë‹˜ ì œì•ˆ: 'ìƒˆë¡œìš´ ë°©ì‹(ì¸ë‚´ì‹¬ ê°•í™”)' ì‘ì „ ì‹œì‘ ===")
    
    s_start = "2026-02-01"
    s_end = datetime.now().strftime("%Y-%m-%d")
    
    # 2. ëˆì§ˆê¸´ ì¬ì‹œë„ ì„¤ì •
    session = requests.Session()
    retry = Retry(
        total=5, # ìµœëŒ€ 5ë²ˆ ì¬ì‹œë„
        backoff_factor=2, # ì¬ì‹œë„ ê°„ê²© ì ì§„ì  ì¦ê°€ (2, 4, 8, 16ì´ˆ...)
        status_forcelist=[500, 502, 503, 504], # í•´ë‹¹ ì—ëŸ¬ ë°œìƒ ì‹œ ì¬ì‹œë„
        raise_on_status=False
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36',
        'Referer': 'https://nedrug.mfds.go.kr/pbp/CCBAE01'
    })

    try:
        # ì²« ì ‘ì† íƒ€ì„ì•„ì›ƒì„ 60ì´ˆë¡œ ì—°ì¥
        print(">> ì‹ì•½ì²˜ ì„œë²„ ì ‘ì† ì‹œë„ ì¤‘ (ìµœëŒ€ 60ì´ˆ ëŒ€ê¸°)...")
        session.get("https://nedrug.mfds.go.kr/pbp/CCBAE01", timeout=60)
        time.sleep(3) # ì ‘ì† í›„ ì ì‹œ íœ´ì‹

        total_saved = 0

        for page in range(1, 6):
            print(f"\n>> [ {page} í˜ì´ì§€ ] ë°ì´í„° ìš”ì²­ ì¤‘...")
            
            payload = {
                'page': page,
                'limit': '10',
                'searchYn': 'true',
                'sDateGb': 'date',
                'sPermitDateStart': s_start,
                'sPermitDateEnd': s_end,
                'btnSearch': 'ê²€ìƒ‰'
            }

            # ë°ì´í„° ìš”ì²­ íƒ€ì„ì•„ì›ƒë„ 60ì´ˆë¡œ ì„¤ì •
            res = session.post("https://nedrug.mfds.go.kr/pbp/CCBAE01/getItemPermitIntro", 
                               headers=session.headers, data=payload, timeout=60)
            
            soup = BeautifulSoup(res.text, 'html.parser')
            rows = soup.select('table.board_list tbody tr')

            if not rows or "ë°ì´í„°ê°€" in rows[0].get_text():
                print("ìˆ˜ì§‘í•  ë°ì´í„°ê°€ ë” ì´ìƒ ì—†ìŠµë‹ˆë‹¤.")
                break

            for row in rows:
                cols = row.find_all('td')
                if len(cols) < 5 or cols[4].get_text(strip=True): continue 

                product_name = cols[1].get_text(strip=True)
                item_seq = cols[1].find('a')['onclick'].split("'")[1]

                print(f"   -> DB ì „ì†¡: {product_name}")
                
                data = {
                    "item_seq": item_seq,
                    "product_name": product_name,
                    "company": cols[2].get_text(strip=True),
                    "approval_date": cols[3].get_text(strip=True),
                    "detail_url": f"https://nedrug.mfds.go.kr/pbp/CCBBB01/getItemDetail?itemSeq={item_seq}"
                }
                
                supabase.table("drug_approvals").upsert(data).execute()
                total_saved += 1
                time.sleep(0.5) # ê°œë³„ ë°ì´í„° ì €ì¥ í›„ ì§§ì€ íœ´ì‹

            time.sleep(3) # í˜ì´ì§€ ì „í™˜ ì „ ì¶©ë¶„í•œ íœ´ì‹

        print(f"\n=== ğŸ† ì„±ê³µ: ì´ {total_saved}ê±´ì´ Supabase ê¸ˆê³ ì— ì•ˆì°©í–ˆìŠµë‹ˆë‹¤! ===")

    except Exception as e:
        print(f"âŒ ìµœì¢… ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main()
