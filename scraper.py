import os
import requests
import time
import math
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
from supabase import create_client, Client

# 1. ì„¤ì •
API_KEY = "2b03726584036b06c8c1c6b3d385a73be48f35cceac5444bcd6c611db5de7972"
URL = os.environ.get("SUPABASE_URL")
KEY = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(URL, KEY)

def get_detail_and_date(item_seq):
    """ [ìƒì„¸ API] ë‚ ì§œ ë° ìƒì„¸ ì •ë³´ ì¡°íšŒ """
    url = "http://apis.data.go.kr/1471000/DrugPrdtPrmsnInfoService07/getDrugPrdtPrmsnDtlInq06"
    params = {'serviceKey': API_KEY, 'item_seq': item_seq, 'numOfRows': '1', 'type': 'xml'}
    try:
        res = requests.get(url, params=params, timeout=10)
        root = ET.fromstring(res.text)
        item = root.find('.//item')
        if not item: return None

        return {
            'date': item.findtext('ITEM_PERMIT_DATE') or item.findtext('PERMIT_DATE'),
            'manu': item.findtext('MANU_METHOD') or "ì •ë³´ì—†ìŒ",
            'ingr': item.findtext('MAIN_ITEM_INGR') or item.findtext('ITEM_INGR_NAME') or "ì •ë³´ì—†ìŒ",
            'effi': BeautifulSoup(item.findtext('EE_DOC_DATA') or "ìƒì„¸ì°¸ì¡°", "html.parser").get_text()[:500]
        }
    except:
        return None

def scan_range(start_page, end_page, list_url):
    """ ì§€ì •ëœ í˜ì´ì§€ ë²”ìœ„ë¥¼ ìŠ¤ìº”í•˜ì—¬ ì €ì¥ (ì €ì¥ëœ ê°œìˆ˜ ë°˜í™˜) """
    saved_count = 0
    # startë¶€í„° endê¹Œì§€ (ìˆœë°©í–¥ ë˜ëŠ” ì—­ë°©í–¥)
    step = 1 if start_page <= end_page else -1
    
    # rangeì˜ ëì€ í¬í•¨ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¡°ì •
    for page in range(start_page, end_page + step, step):
        if page < 1: continue
        
        print(f">> [ìŠ¤ìº”] {page}í˜ì´ì§€ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤...")
        try:
            params = {'serviceKey': API_KEY, 'pageNo': str(page), 'numOfRows': '100', 'type': 'xml'}
            res = requests.get(list_url, params=params, timeout=30)
            items = ET.fromstring(res.text).findall('.//item')
            
            if not items: continue

            # í•œ í˜ì´ì§€ ë‚´ì˜ ì•„ì´í…œ ì „ìˆ˜ ê²€ì‚¬
            for item in items:
                item_seq = item.findtext('ITEM_SEQ')
                product_name = item.findtext('ITEM_NAME')
                
                # ìƒì„¸ ì¡°íšŒë¡œ ë‚ ì§œ í™•ì¸
                detail = get_detail_and_date(item_seq)
                if not detail or not detail['date']: continue
                
                real_date = detail['date'].replace("-", "").replace(".", "")
                
                # ğŸ¯ íƒ€ê²Ÿ: 2026ë…„ 2ì›” 1ì¼ ~ 2ì›” 14ì¼ (ë©ˆì¶”ì§€ ì•Šê³  ê³„ì† ì°¾ìŒ)
                if "20260201" <= real_date <= "20260214":
                    print(f"   -> [í¬ì°©!] {product_name} ({real_date})")
                    
                    data = {
                        "item_seq": item_seq,
                        "product_name": product_name,
                        "company": item.findtext('ENTP_NAME'),
                        "manufacturer": detail['manu'],
                        "category": item.findtext('SPCLTY_PBLC') or "êµ¬ë¶„ì—†ìŒ",
                        "approval_type": item.findtext('PRDUCT_TYPE_NAME') or "ì •ìƒ",
                        "ingredients": detail['ingr'],
                        "efficacy": detail['effi'],
                        "approval_date": real_date,
                        "detail_url": f"https://nedrug.mfds.go.kr/pbp/CCBBB01/getItemDetail?itemSeq={item_seq}"
                    }
                    supabase.table("drug_approvals").upsert(data).execute()
                    saved_count += 1
                    time.sleep(0.05) # API ë§¤ë„ˆ í˜¸ì¶œ
                    
        except Exception as e:
            print(f"âš ï¸ {page}í˜ì´ì§€ ì—ëŸ¬: {e}")
            continue
            
    return saved_count

def main():
    print("=== ğŸŒŸ ì…˜ íŒ€ì¥ë‹˜ ì§€ì‹œ: 'ì–‘ë™ì‘ì „' (ì•ë’¤ ì „ìˆ˜ì¡°ì‚¬) ì‹œì‘ ===")
    list_url = "http://apis.data.go.kr/1471000/DrugPrdtPrmsnInfoService07/getDrugPrdtPrmsnInq07"
    
    # [1ë‹¨ê³„] ì „ì²´ í˜ì´ì§€ ìˆ˜ ê³„ì‚°
    print(">> [ì •ì°°] ì „ì²´ ë°ì´í„° ê·œëª¨ íŒŒì•… ì¤‘...")
    try:
        res = requests.get(list_url, params={'serviceKey': API_KEY, 'numOfRows': '1', 'type': 'xml'}, timeout=10)
        total_count = int(ET.fromstring(res.text).findtext('.//totalCount'))
        last_page = math.ceil(total_count / 100)
        print(f">> ì´ {total_count}ê±´ (ì•½ {last_page}í˜ì´ì§€)")
    except:
        print("âŒ API ì ‘ì† ì‹¤íŒ¨")
        return

    total_saved = 0

    # [2ë‹¨ê³„] ë’·ë¬¸ ê³µëµ (ë§ˆì§€ë§‰ 5í˜ì´ì§€: ë³´í†µ ì—¬ê¸°ì— ìµœì‹  ë°ì´í„°ê°€ ìˆìŒ)
    # ë’¤ì£½ë°•ì£½ ì„ì—¬ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ë„‰ë„‰í•˜ê²Œ ë’¤ì—ì„œ 10í˜ì´ì§€ ê²€ì‚¬
    print("\nğŸš€ [ì‘ì „1] ë’·ë¬¸ ê³µëµ (ìµœì‹  ë°ì´í„° ì¶”ì • êµ¬ì—­)")
    total_saved += scan_range(last_page, last_page - 10, list_url)

    # [3ë‹¨ê³„] ì•ë¬¸ ê³µëµ (ì²˜ìŒ 5í˜ì´ì§€: í˜¹ì‹œ ì—­ìˆœ ì •ë ¬ì¼ ê²½ìš° ëŒ€ë¹„)
    print("\nğŸš€ [ì‘ì „2] ì•ë¬¸ ê³µëµ (í˜¹ì‹œ ëª¨ë¥¼ ì—­ìˆœ ëŒ€ë¹„)")
    total_saved += scan_range(1, 5, list_url)

    print(f"\n=== ğŸ† ì‘ì „ ì¢…ë£Œ: ì´ {total_saved}ê±´(ëª©í‘œ 43ê±´) í™•ë³´ ì™„ë£Œ! ===")

if __name__ == "__main__":
    main()
