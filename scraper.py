import os
import requests
import time
import math
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
from supabase import create_client, Client

# 1. ì„¤ì •
API_KEY = "2b03726584036b06c8c1c6b3d385a73be48f35cceac5444bcd6c611db5de7972"
URL = os.environ.get("SUPABASE_URL")
KEY = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(URL, KEY)

# ì›¹ í¬ë¡¤ë§ìš© ì„¸ì…˜
session = requests.Session()
session.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
    'Referer': 'https://nedrug.mfds.go.kr/'
})

def clean_text(text):
    if not text: return ""
    return " ".join(text.split())

def get_web_detail_parsing(item_seq):
    url = f"https://nedrug.mfds.go.kr/pbp/CCBBB01/getItemDetail?itemSeq={item_seq}"
    try:
        res = session.get(url, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # 1. í—ˆê°€ì‹¬ì‚¬ìœ í˜•
        approval_type = "ì •ë³´ì—†ìŒ"
        table_rows = soup.select("table tbody tr")
        for row in table_rows:
            th = row.select_one("th")
            if th and "í—ˆê°€ì‹¬ì‚¬ìœ í˜•" in th.text:
                td = row.select_one("td")
                if td: approval_type = clean_text(td.text)
                break
        
        # 2. íš¨ëŠ¥íš¨ê³¼
        efficacy = "ìƒì„¸ë‚´ìš© ì°¸ì¡°"
        ee_tag = soup.select_one("#ee_doc_data")
        if not ee_tag:
            for row in table_rows:
                th = row.select_one("th")
                if th and "íš¨ëŠ¥" in th.text:
                    ee_tag = row.select_one("td")
                    break
        if ee_tag:
            efficacy = clean_text(ee_tag.get_text(separator=" "))
            if len(efficacy) > 500: efficacy = efficacy[:500] + "..."

        return {'approval_type': approval_type, 'efficacy': efficacy}
    except:
        return None

def main():
    print("=== ğŸŒŸ ì…˜ íŒ€ì¥ë‹˜ ì§€ì‹œ: ì•± í˜¸í™˜ì„±ì„ ìœ„í•´ ì»¬ëŸ¼ëª…ì€ ì˜ì–´(efficacy)ë¡œ ìœ ì§€! ===")
    
    list_url = "http://apis.data.go.kr/1471000/DrugPrdtPrmsnInfoService07/getDrugPrdtPrmsnInq07"
    
    print(">> [ì •ì°°] ë°ì´í„° í™•ì¸ ì¤‘...")
    try:
        res = requests.get(list_url, params={'serviceKey': API_KEY, 'numOfRows': '1', 'type': 'xml'}, timeout=10)
        total_count = int(ET.fromstring(res.text).findtext('.//totalCount'))
        last_page = math.ceil(total_count / 100)
    except:
        return

    total_saved = 0
    scan_range = 200
    start_page = last_page
    end_page = max(1, last_page - scan_range)
    
    for page in range(start_page, end_page, -1):
        if page % 10 == 0:
            print(f">> [ì§„í–‰] {page}í˜ì´ì§€... (í˜„ì¬ {total_saved}ê±´)")
            
        try:
            params = {'serviceKey': API_KEY, 'pageNo': str(page), 'numOfRows': '100', 'type': 'xml'}
            res = requests.get(list_url, params=params, timeout=30)
            items = ET.fromstring(res.text).findall('.//item')
            if not items: continue

            for item in reversed(items):
                if item.findtext('CANCEL_DATE'): continue
                code = item.findtext('PRDLST_STDR_CODE') or ""
                if not code.startswith("2026"): continue 
                
                item_seq = item.findtext('ITEM_SEQ')
                real_date = (item.findtext('ITEM_PERMIT_DATE') or "").replace("-", "")

                if real_date >= "20260201":
                    web_detail = get_web_detail_parsing(item_seq) or {'approval_type': 'í™•ì¸ë¶ˆê°€', 'efficacy': 'í™•ì¸ë¶ˆê°€'}

                    print(f"   -> [ğŸ’ì €ì¥] {item.findtext('ITEM_NAME')}")
                    
                    data = {
                        "item_seq": item_seq,
                        "product_name": item.findtext('ITEM_NAME'),
                        "company": item.findtext('ENTP_NAME'),
                        "category": item.findtext('SPCLTY_PBLC') or "êµ¬ë¶„ì—†ìŒ",
                        "ingredients": item.findtext('MAIN_ITEM_INGR') or "ì •ë³´ì—†ìŒ",
                        
                        # [í•µì‹¬ ìˆ˜ì •] ì™¼ìª½(Key)ì€ ì˜ì–´, ì˜¤ë¥¸ìª½(Value)ì€ í•œê¸€ ë°ì´í„°
                        "efficacy": web_detail['efficacy'],         
                        "approval_type": web_detail['approval_type'], 
                        
                        "approval_date": real_date,
                        "detail_url": f"https://nedrug.mfds.go.kr/pbp/CCBBB01/getItemDetail?itemSeq={item_seq}"
                    }
                    supabase.table("drug_approvals").upsert(data).execute()
                    total_saved += 1
                    time.sleep(0.5)
        except: continue

    print(f"\n=== ğŸ† ì €ì¥ ì™„ë£Œ: ì•±ì´ ì¢‹ì•„í•˜ëŠ” ì˜ì–´ ì´ë¦„í‘œë¡œ ì˜ ë¶™ì˜€ìŠµë‹ˆë‹¤! ===")

if __name__ == "__main__":
    main()
