import os
import requests
import time
import random
from bs4 import BeautifulSoup
from supabase import create_client, Client

# 1. ì„¤ì •
URL = os.environ.get("SUPABASE_URL")
KEY = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(URL, KEY)

def get_web_detail(session, item_seq):
    """
    [ìƒì„¸ ìˆ˜ì§‘] ì œí’ˆëª…ì„ í´ë¦­í–ˆì„ ë•Œ ë‚˜ì˜¤ëŠ” í™”ë©´(CCBBB01)ì˜ ë°ì´í„°ë¥¼ ê¸ì–´ì˜µë‹ˆë‹¤.
    """
    url = f"https://nedrug.mfds.go.kr/pbp/CCBBB01/getItemDetail?itemSeq={item_seq}"
    try:
        res = session.get(url, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # 1. ìœ„íƒì œì¡°ì—…ì²´ (í…Œì´ë¸” ë’¤ì§€ê¸°)
        manufacturer = "ìì‚¬ì œì¡°" 
        tables = soup.select("table.view_table")
        for table in tables:
            if "ì œì¡°ì†Œ" in table.text:
                rows = table.select("tr")
                for row in rows:
                    if "ìœ„íƒ" in row.text or "ìˆ˜íƒ" in row.text:
                        # ìœ„íƒì—…ì²´ëª…ì´ ìˆëŠ” tdë¥¼ ì°¾ì•„ì„œ ì¶”ì¶œ
                        manufacturer = row.select_one("td").text.strip()
                        break
        
        # 2. ì„±ë¶„ëª… (ê¸°ë³¸ ê°œìš” íƒ­ ë“±ì—ì„œ ì¶”ì¶œ ì‹œë„)
        ingredients = "ìƒì„¸ì„±ë¶„ ì°¸ì¡°"
        # ì„±ë¶„ì€ ë³´í†µ ë³„ë„ íƒ­ì´ë‚˜ ë³µì¡í•œ êµ¬ì¡°ë¼, ê°„ë‹¨íˆ ìŠ¤í‚µí•˜ê±°ë‚˜ ë©”íƒ€ë°ì´í„° í™œìš©
        
        # 3. íš¨ëŠ¥íš¨ê³¼ (IDë¡œ ì¶”ì¶œ)
        efficacy = "ìƒì„¸ íš¨ëŠ¥íš¨ê³¼ ì°¸ì¡°"
        ee_data = soup.select_one("#ee_doc_data")
        if ee_data:
            efficacy = ee_data.text.strip()[:500] # 500ì ìš”ì•½

        return manufacturer, ingredients, efficacy

    except Exception:
        return "ìˆ˜ì§‘ì‹¤íŒ¨", "ìˆ˜ì§‘ì‹¤íŒ¨", "ìˆ˜ì§‘ì‹¤íŒ¨"

def main():
    print("=== ğŸŒŸ ì…˜ íŒ€ì¥ë‹˜ ì „ëµ: 'ìœ íš¨ í—ˆê°€(ì·¨ì†ŒX)' ì˜ì•½í’ˆë§Œ ì •ë°€ íƒ€ê²© ===")
    
    session = requests.Session()
    # ë´‡ ì°¨ë‹¨ íšŒí”¼ìš© í—¤ë”
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
        'Referer': 'https://nedrug.mfds.go.kr/pbp/CCBAE01'
    }
    
    # [1ë‹¨ê³„] íŒ€ì¥ë‹˜ì´ ì£¼ì‹  'ì£¼ê°„ ê²€ìƒ‰' URL (2ì›” 2ì£¼ì°¨)
    target_url = "https://nedrug.mfds.go.kr/pbp/CCBAE01/getItemPermitIntro"
    
    # í˜ì´ì§€ ìˆœíšŒ (ë°ì´í„°ê°€ ë§ì„ ìˆ˜ ìˆìœ¼ë‹ˆ 1~5í˜ì´ì§€)
    for page in range(1, 6):
        print(f"\n>> [Web] {page}í˜ì´ì§€ ëª©ë¡ ê²€ì‚¬ ì¤‘...")
        
        # íŒŒë¼ë¯¸í„° ì„¸íŒ… (íŒ€ì¥ë‹˜ URL ê¸°ì¤€)
        params = {
            'page': page,
            'limit': '10',
            'sort': 'itemPermitDate', # í—ˆê°€ì¼ììˆœ ì •ë ¬
            'sortOrder': 'true',      # ë‚´ë¦¼ì°¨ìˆœ(ìµœì‹ ìˆœ) ì¶”ì •
            'searchYn': 'true',
            'sDateGb': 'week',        # ì£¼ê°„ ê²€ìƒ‰
            'sYear': '2026',
            'sMonth': '2',
            'sWeek': '2',
            'sPermitDateStart': '2026-02-08',
            'sPermitDateEnd': '2026-02-14',
            'btnSearch': 'ê²€ìƒ‰'
        }

        try:
            # ëª©ë¡ í˜ì´ì§€ ì ‘ì†
            res = session.get(target_url, params=params, headers=headers, timeout=30)
            soup = BeautifulSoup(res.text, 'html.parser')
            rows = soup.select('table.board_list tbody tr')

            if not rows or "ë°ì´í„°ê°€" in rows[0].text:
                print(">> ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì™„ë£Œ)")
                break

            for row in rows:
                cols = row.find_all('td')
                if len(cols) < 8: continue # ì»¬ëŸ¼ ìˆ˜ í™•ì¸

                # ì»¬ëŸ¼ ë§¤í•‘ (ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë”°ë¼ ì¸ë±ìŠ¤ ì¡°ì • í•„ìš”)
                # ìˆœë²ˆ(0) / ì œí’ˆëª…(1) / ì—…ì²´ëª…(2) / í—ˆê°€ì¼ì(3) / ì·¨ì†Œì·¨í•˜ì¼ì(4) ...
                product_name = cols[1].text.strip()
                company = cols[2].text.strip()
                approval_date = cols[3].text.strip()
                cancel_date = cols[4].text.strip() # ì—¬ê¸°ê°€ í•µì‹¬!

                # [2ë‹¨ê³„] í•„í„°ë§: 'ì·¨ì†Œ/ì·¨í•˜ì¼ì'ê°€ ë¹„ì–´ìˆì–´ì•¼ ìˆ˜ì§‘
                if cancel_date != "":
                    print(f"   -> [íŒ¨ìŠ¤] {product_name} (ì·¨ì†Œë¨: {cancel_date})")
                    continue
                
                # ìœ íš¨í•œ ì•½í’ˆë§Œ ì§„í–‰
                try:
                    # onclick="goDetail('202612345');" í˜•íƒœì—ì„œ ID ì¶”ì¶œ
                    item_seq = cols[1].find('a')['onclick'].split("'")[1]
                except:
                    continue

                print(f"   -> [ìˆ˜ì§‘] {product_name} ({approval_date}) - ìƒì„¸ ì •ë³´ ê¸ëŠ” ì¤‘...")
                
                # [3ë‹¨ê³„] ìƒì„¸ í˜ì´ì§€ ì¹¨íˆ¬ (í´ë¦­ í–‰ë™ ëª¨ë°©)
                manufacturer, ingredients, efficacy = get_web_detail(session, item_seq)

                # [4ë‹¨ê³„] ë¦¬ìŠ¤íŠ¸(í‘œ)ì— ë°˜ì˜
                data = {
                    "item_seq": item_seq,
                    "product_name": product_name,
                    "company": company,
                    "manufacturer": manufacturer, 
                    "category": "ì „ë¬¸ì˜ì•½í’ˆ" if "ì „ë¬¸" in cols[5].text else "ì¼ë°˜ì˜ì•½í’ˆ", # 5,6ë²ˆ ì»¬ëŸ¼ ì¯¤ì— êµ¬ë¶„ ì¡´ì¬
                    "approval_type": "ì •ìƒ",
                    "ingredients": ingredients,
                    "efficacy": efficacy,
                    "approval_date": approval_date,
                    "detail_url": f"https://nedrug.mfds.go.kr/pbp/CCBBB01/getItemDetail?itemSeq={item_seq}"
                }
                
                supabase.table("drug_approvals").upsert(data).execute()
                time.sleep(random.uniform(0.5, 1.0)) # ë´‡ íƒì§€ ë°©ì§€ í…€

        except Exception as e:
            print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ: {e}")
            continue

    print(f"\n=== ğŸ† ì‘ì „ ì™„ë£Œ: ì·¨ì†Œëœ ì•½ì€ ë²„ë¦¬ê³  ì•Œì§œë°°ê¸°ë§Œ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤! ===")

if __name__ == "__main__":
    main()
