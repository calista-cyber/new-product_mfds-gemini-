import os
import requests
import time
import random
from datetime import datetime
from bs4 import BeautifulSoup
from supabase import create_client, Client

# 1. Supabase ì—°ê²°
URL = os.environ.get("SUPABASE_URL")
KEY = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(URL, KEY)

def main():
    print("=== ğŸ›¡ï¸ ì…˜ íŒ€ì¥ë‹˜ ì „ìš©: ì•¼ê°„ ë§¤ë³µ ë°ì´í„° ì¸ì¶œ ì‘ì „ ì‹œì‘ ===")
    
    s_start = "2026-02-01"
    s_end = datetime.now().strftime("%Y-%m-%d")
    
    # ë´‡ ê°ì§€ë¥¼ í”¼í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ì´ë¦„í‘œ(User-Agent) ì¤€ë¹„
    user_agents = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'
    ]

    session = requests.Session()
    
    try:
        # ë¬´ì‘ìœ„ ì´ë¦„í‘œ ì„ íƒ
        session.headers.update({'User-Agent': random.choice(user_agents), 'Referer': 'https://nedrug.mfds.go.kr/pbp/CCBAE01'})
        session.get("https://nedrug.mfds.go.kr/pbp/CCBAE01", timeout=40)
        time.sleep(random.uniform(5, 10)) # ì¶©ë¶„í•œ ì´ˆê¸° ëŒ€ê¸°

        total_saved = 0
        pages = [1, 2, 3, 4, 5]
        random.shuffle(pages)

        for page in pages:
            print(f"\n>> [ {page} í˜ì´ì§€ ] ë§¤ë³µ ì¹¨íˆ¬ ì¤‘...")
            payload = {'page': page, 'searchYn': 'true', 'sDateGb': 'date', 'sPermitDateStart': s_start, 'sPermitDateEnd': s_end, 'btnSearch': 'ê²€ìƒ‰'}

            # ìš”ì²­ ë³´ë‚¼ ë•Œë§ˆë‹¤ ì´ë¦„í‘œ êµì²´
            session.headers.update({'User-Agent': random.choice(user_agents)})
            res = session.post("https://nedrug.mfds.go.kr/pbp/CCBAE01/getItemPermitIntro", data=payload, timeout=50)
            
            if "board_list" not in res.text or "ë°ì´í„°ê°€" in res.text:
                print(f"âš ï¸ {page}í˜ì´ì§€: ì„œë²„ê°€ ê°ì‹œ ì¤‘ì…ë‹ˆë‹¤. 30ì´ˆê°„ ë§¤ë³µ(ëŒ€ê¸°)...")
                time.sleep(30)
                continue

            soup = BeautifulSoup(res.text, 'html.parser')
            rows = soup.select('table.board_list tbody tr')

            for row in rows:
                cols = row.find_all('td')
                if len(cols) < 5: continue

                product_name = cols[1].get_text(strip=True)
                item_seq = cols[1].find('a')['onclick'].split("'")[1]

                print(f"   -> DB ì „ì†¡: {product_name}")
                data = {
                    "item_seq": item_seq, "product_name": product_name, "company": cols[2].get_text(strip=True),
                    "approval_date": cols[3].get_text(strip=True),
                    "detail_url": f"https://nedrug.mfds.go.kr/pbp/CCBBB01/getItemDetail?itemSeq={item_seq}"
                }
                
                supabase.table("drug_approvals").upsert(data).execute()
                total_saved += 1
                time.sleep(random.uniform(2, 5)) # ë°ì´í„° ê°„ ê¸´ íœ´ì‹

            time.sleep(random.uniform(10, 20)) # í˜ì´ì§€ ê°„ ê¸´ íœ´ì‹

        print(f"\n=== ğŸ† ì‘ì „ ì¢…ë£Œ: ì´ {total_saved}ê±´ ì•ˆì°©! ===")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
